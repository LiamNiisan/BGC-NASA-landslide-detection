{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9ed07a-d261-4644-b491-cafda964330e",
   "metadata": {},
   "source": [
    "# Location Positive/Negative Sentence Classification\n",
    "- Building a logistic regression model to detect whether a sentence contains the gold location description keywords\n",
    "- Train on the processed NASA example (through Badr's model) `new_filter_train_set.csv` and predicted on the `article_sample.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8a24bc-1f5e-4656-88b6-f2f900acefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from collections import defaultdict\n",
    "import geocoder\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dda7ff-4a0e-4e6d-88a2-48c1d40ed538",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a07763-34f5-470d-8837-9cab163cbd2c",
   "metadata": {},
   "source": [
    "- Get the POS/NEG label for each sentence\n",
    "    - First do exact match: if `location_description` appears in `text`, mark the sentence as a positive sentence (`pos_setence=Yes`), otherwise, mark the sentence as a negative sentence (`pos_setence=No`).\n",
    "    - Then do partial match: if one or more location entities in the sentence appear in the gold label (`location_description`), mark the sentence as a positive sentence (`pos_setence=Yes`), otherwise, mark the sentence as a negative sentence (`pos_setence=No`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9828bc13-c7c3-4286-807f-da443b83c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_locs_dates(data):\n",
    "    \"\"\"Fill NAs and merge location/date columns\"\"\"\n",
    "    data = data.fillna('')  # replace NAN with empty string\n",
    "    data['locations'] = data[['GPE', 'LOC']].agg('|'.join, axis=1)  # join GPE and LOC by |\n",
    "    data['dates'] = data[['DATE','TIME']].agg('|'.join, axis=1)  # join DATE and TIME by |\n",
    "    data = data.drop(columns=['GPE', 'LOC', 'DATE', 'TIME'])  # keep only the joined column\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cc6c34-deff-4987-b276-570882a5f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(nasa, ner):\n",
    "    \"\"\"\n",
    "    prepare data for pos sentence prediction model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nasa : pandas DataFrame\n",
    "        nasa dataset containing location_description\n",
    "    ner : pandas DataFrame\n",
    "        dataset containing id, text, GPE, LOC, DATE, TIME columns from previous step\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        a pandas DataFrame with id, text, location_description, locations, dates, pos_sentence columns\n",
    "    \"\"\"\n",
    "    nasa = nasa.reset_index()\n",
    "    nasa = nasa.rename(columns={\"index\": \"id\"})  # id: index in NASA dataset\n",
    "    df = pd.merge(ner, nasa, how='left', on='id')\n",
    "    df = merge_locs_dates(df[['id', 'text', 'location_description', 'GPE', 'LOC', 'DATE', 'TIME']])\n",
    "    \n",
    "    data = df.to_dict()  # transform dataframe into dictionary\n",
    "\n",
    "    data['pos_sentence'] = {}\n",
    "    n = defaultdict(int)\n",
    "    data['number_of_pos_sent'] = {}\n",
    "    data['contain_pos_sent'] = {}\n",
    "\n",
    "    # exact match\n",
    "    # iterate over each sentence in the data\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['location_description'][i] in data['text'][i]:\n",
    "            data['pos_sentence'][i] = 'Yes'\n",
    "            n[data['id'][i]] += 1\n",
    "        else:\n",
    "            data['pos_sentence'][i] = 'No'\n",
    "\n",
    "    # partial match\n",
    "    for i in range(len(data['text'])):\n",
    "        if n[data['id'][i]] == 0:\n",
    "            locs = list(filter(None, data['locations'][i].split(\"|\"))) \n",
    "            if any(loc in data['location_description'][i] for loc in locs):\n",
    "                data['pos_sentence'][i] = 'Yes'\n",
    "                n[data['id'][i]] += 1\n",
    "            else:\n",
    "                data['pos_sentence'][i] = 'No'\n",
    "    \n",
    "    # count how many pos_sentence each document has\n",
    "    # count how many documents contain gold place name, how many doesn't\n",
    "    for i in range(len(data['text'])):\n",
    "        if n[data['id'][i]] == 0:\n",
    "            data['number_of_pos_sent'][i] = 0\n",
    "            data['contain_pos_sent'][i] = False\n",
    "        else:\n",
    "            data['number_of_pos_sent'][i] = n[data['id'][i]]\n",
    "            data['contain_pos_sent'][i] = True\n",
    "        \n",
    "    return pd.DataFrame(data)[pd.DataFrame(data)['contain_pos_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0e0ab3-15e5-4387-9d04-1e3f97701a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>location_description</th>\n",
       "      <th>locations</th>\n",
       "      <th>dates</th>\n",
       "      <th>pos_sentence</th>\n",
       "      <th>number_of_pos_sent</th>\n",
       "      <th>contain_pos_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Reported By: | Edited By: |Source: ANI |Update...</td>\n",
       "      <td>Dabhol village of Maharashtra's Ratnagiri dist...</td>\n",
       "      <td>|</td>\n",
       "      <td>Aug 04 , 2015|11:39 AM IST</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>At least 12 people are feared to be buried und...</td>\n",
       "      <td>Dabhol village of Maharashtra's Ratnagiri dist...</td>\n",
       "      <td>Dabhol|Maharashtra|Ratnagiri|</td>\n",
       "      <td>|</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The landslide is said to have taken place at 3...</td>\n",
       "      <td>Dabhol village of Maharashtra's Ratnagiri dist...</td>\n",
       "      <td>|</td>\n",
       "      <td>|3:30 am</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ratnagiri (Maharashtra): Landslide occurred at...</td>\n",
       "      <td>Dabhol village of Maharashtra's Ratnagiri dist...</td>\n",
       "      <td>Ratnagiri|Maharashtra|</td>\n",
       "      <td>|3 : 30 am today</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pic.twitter.com/MOcmTxnAZX June 22, 2015</td>\n",
       "      <td>Dabhol village of Maharashtra's Ratnagiri dist...</td>\n",
       "      <td>|</td>\n",
       "      <td>June 22 , 2015|</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26128</th>\n",
       "      <td>35646</td>\n",
       "      <td>Meanwhile, the Kanchanjunga Academy Higher Sec...</td>\n",
       "      <td>Phidim-Raanke section of the Mechi Highway at ...</td>\n",
       "      <td>Phidim-1|</td>\n",
       "      <td>|</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26129</th>\n",
       "      <td>35649</td>\n",
       "      <td>Follow us on landslide blocks doda batote high...</td>\n",
       "      <td>Chakwa bridge, 9 kilomters short of Doda</td>\n",
       "      <td>Jammu|</td>\n",
       "      <td>|</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26130</th>\n",
       "      <td>35649</td>\n",
       "      <td>The highway was blocked after a landslide hit ...</td>\n",
       "      <td>Chakwa bridge, 9 kilomters short of Doda</td>\n",
       "      <td>Doda|</td>\n",
       "      <td>|last evening</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26131</th>\n",
       "      <td>35649</td>\n",
       "      <td>He said that the work to open the highway was ...</td>\n",
       "      <td>Chakwa bridge, 9 kilomters short of Doda</td>\n",
       "      <td>|</td>\n",
       "      <td>today|evening</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26132</th>\n",
       "      <td>35649</td>\n",
       "      <td>“If there is no rain, we might throw the road ...</td>\n",
       "      <td>Chakwa bridge, 9 kilomters short of Doda</td>\n",
       "      <td>|</td>\n",
       "      <td>today|evening</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22354 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "0          0  Reported By: | Edited By: |Source: ANI |Update...   \n",
       "1          0  At least 12 people are feared to be buried und...   \n",
       "2          0  The landslide is said to have taken place at 3...   \n",
       "3          0  Ratnagiri (Maharashtra): Landslide occurred at...   \n",
       "4          0           pic.twitter.com/MOcmTxnAZX June 22, 2015   \n",
       "...      ...                                                ...   \n",
       "26128  35646  Meanwhile, the Kanchanjunga Academy Higher Sec...   \n",
       "26129  35649  Follow us on landslide blocks doda batote high...   \n",
       "26130  35649  The highway was blocked after a landslide hit ...   \n",
       "26131  35649  He said that the work to open the highway was ...   \n",
       "26132  35649  “If there is no rain, we might throw the road ...   \n",
       "\n",
       "                                    location_description  \\\n",
       "0      Dabhol village of Maharashtra's Ratnagiri dist...   \n",
       "1      Dabhol village of Maharashtra's Ratnagiri dist...   \n",
       "2      Dabhol village of Maharashtra's Ratnagiri dist...   \n",
       "3      Dabhol village of Maharashtra's Ratnagiri dist...   \n",
       "4      Dabhol village of Maharashtra's Ratnagiri dist...   \n",
       "...                                                  ...   \n",
       "26128  Phidim-Raanke section of the Mechi Highway at ...   \n",
       "26129           Chakwa bridge, 9 kilomters short of Doda   \n",
       "26130           Chakwa bridge, 9 kilomters short of Doda   \n",
       "26131           Chakwa bridge, 9 kilomters short of Doda   \n",
       "26132           Chakwa bridge, 9 kilomters short of Doda   \n",
       "\n",
       "                           locations                       dates pos_sentence  \\\n",
       "0                                  |  Aug 04 , 2015|11:39 AM IST           No   \n",
       "1      Dabhol|Maharashtra|Ratnagiri|                           |          Yes   \n",
       "2                                  |                    |3:30 am           No   \n",
       "3             Ratnagiri|Maharashtra|            |3 : 30 am today           No   \n",
       "4                                  |             June 22 , 2015|           No   \n",
       "...                              ...                         ...          ...   \n",
       "26128                      Phidim-1|                           |           No   \n",
       "26129                         Jammu|                           |           No   \n",
       "26130                          Doda|               |last evening          Yes   \n",
       "26131                              |               today|evening           No   \n",
       "26132                              |               today|evening           No   \n",
       "\n",
       "       number_of_pos_sent  contain_pos_sent  \n",
       "0                       1              True  \n",
       "1                       1              True  \n",
       "2                       1              True  \n",
       "3                       1              True  \n",
       "4                       1              True  \n",
       "...                   ...               ...  \n",
       "26128                   1              True  \n",
       "26129                   1              True  \n",
       "26130                   1              True  \n",
       "26131                   1              True  \n",
       "26132                   1              True  \n",
       "\n",
       "[22354 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa = pd.read_csv(\"../data/nasa_global_landslide_catalog_point.csv\")\n",
    "ner = pd.read_csv('../data/new_filter_train_set.csv', index_col=0) \n",
    "data = preprocess(nasa, ner)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87800d69-879a-4b61-b96f-1e78fa017938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of number of positive sentence each document has: \n",
      "1     2498\n",
      "2       74\n",
      "3       29\n",
      "4       11\n",
      "5        6\n",
      "6        6\n",
      "7        2\n",
      "8        1\n",
      "9        4\n",
      "10       3\n",
      "11       1\n",
      "12       1\n",
      "13       4\n",
      "18       1\n",
      "19       1\n",
      "Name: number_of_pos_sent, dtype: int64\n",
      "\n",
      "How many documents contain gold place name: \n",
      "True    2642\n",
      "Name: contain_pos_sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "describe_df = data[['id', 'number_of_pos_sent', 'contain_pos_sent']].drop_duplicates()\n",
    "print(f\"Distribution of number of positive sentence each document has: \\n{describe_df['number_of_pos_sent'].value_counts().sort_index()}\\n\")\n",
    "print(f\"How many documents contain gold place name: \\n{describe_df['contain_pos_sent'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6fdfc-f764-4fc4-ae57-18b244d4bad7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0316653f-00a5-4a77-b035-e28e3eefab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    \"\"\"Train and return the model for pos sentence prediction\"\"\"\n",
    "    df_train, df_test = train_test_split(data, test_size=0.20, random_state=123)  # shuffle=False, \n",
    "    X_train, y_train = df_train[\"text\"], df_train[\"pos_sentence\"]\n",
    "    X_test, y_test = df_test[\"text\"], df_test[\"pos_sentence\"]\n",
    "    \n",
    "    model = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
    "    model.fit(X_train, y_train)\n",
    "    test_scores = classification_report(y_test, model.predict(X_test))\n",
    "    \n",
    "    return model, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5035ca-eb4e-4116-bc41-8add8c604066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_scores = train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8905c1-c00f-4913-92fe-cc89077bd7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.83      0.87      3871\n",
      "         Yes       0.34      0.58      0.43       600\n",
      "\n",
      "    accuracy                           0.79      4471\n",
      "   macro avg       0.63      0.70      0.65      4471\n",
      "weighted avg       0.85      0.79      0.81      4471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec46897-8506-4678-b2a5-b38275908645",
   "metadata": {},
   "source": [
    "## 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d3c045-a12b-4664-a4c0-cddfc050c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(p1, p2):\n",
    "    \"\"\"Get the geographical distance between two points\"\"\"\n",
    "    if p1 and p2:\n",
    "        return round(geopy.distance.geodesic(p1, p2).km, 3)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6e27d8-7d76-47ac-8e8b-a92bf072a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_idx(centroid, points):\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "        centroid: a tuple of centroid;\n",
    "        points: a list of tuples\n",
    "    Return:\n",
    "        the index of the point that should be removed\n",
    "    \"\"\"\n",
    "    dists = [get_distance(centroid, point) for point in points]\n",
    "    return dists.index(max(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e78b1c6-f9db-40f8-8f02-8a3d283e5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smallest_region_idx(locs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    locs : list of dictionary\n",
    "        a list of dictionary containing latitude, longitude, \n",
    "        northeast point, southwest point for all the location \n",
    "        entities in the positive sentence\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        an integer indicating the index of the location entity \n",
    "        that has the smallest region\n",
    "    \"\"\"\n",
    "    dists = [get_distance(loc['northeast'], loc['southwest']) for loc in locs]\n",
    "    return dists.index(min(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4098219c-4e90-4722-a912-6baf0a2f594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, model):   # df=example, model=best_model\n",
    "    \"\"\"Get the most likely locations, latitude, longitude based on pred model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        a data frame containing document ID (id) and tokenized sentences (text) for each document, \n",
    "        extracted location entities (locations), and extracted date entities (dates)\n",
    "    model:\n",
    "        the prediction model (logistic model trained on NASA dataset)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        a data frame with locations, the most likely location, latitude, longitude, diameter\n",
    "    \"\"\"\n",
    "    df = merge_locs_dates(df)\n",
    "    \n",
    "    # get predict_proba\n",
    "    pd.options.mode.chained_assignment = None   # silent warning message\n",
    "    df['predict_proba'] = model.predict_proba(df['text'])[:, 1]\n",
    "\n",
    "    result = {'locations': defaultdict(str),\n",
    "              'location': defaultdict(str),\n",
    "              'latitude': defaultdict(float),\n",
    "              'longitude': defaultdict(float),\n",
    "              'diameter_km': defaultdict(float)}\n",
    "\n",
    "    # get a dict of idxmax for each document\n",
    "    idx_max = df.groupby('id')['predict_proba'].idxmax().to_dict()\n",
    "\n",
    "    data = df.to_dict()\n",
    "    for i, idx in idx_max.items():  # i: index of the document; idx: index of the df\n",
    "        # ensure the `locations` column of the `idxmax` row is not empty \n",
    "        current_proba = df.query('id == @i')['predict_proba']\n",
    "        while data['locations'][idx] == \"|\":\n",
    "            try:\n",
    "                current_proba = current_proba.drop(idx)  # drop the current idxmax\n",
    "                idx = current_proba.idxmax()  # get the idxmax of the rest\n",
    "            except ValueError:\n",
    "                print(f\"All locations in document {i} are empty!\") \n",
    "                idx = -1  # set idx=-1 if all locations are empty\n",
    "                break\n",
    "        \n",
    "        # store the locations, latitude, longitude in result dict\n",
    "        if idx != -1:\n",
    "            result['locations'][i] = data['locations'][idx]\n",
    "\n",
    "            locs = list(filter(None, data['locations'][idx].split(\"|\")))\n",
    "            geolocs = []\n",
    "            for loc in locs:\n",
    "                geocoded = geocoder.arcgis(loc).json\n",
    "                if geocoded:\n",
    "                    geoloc = geocoded['bbox']\n",
    "                    geoloc['lat'], geoloc['lng'] = geocoded['lat'], geocoded['lng']\n",
    "                    geolocs.append(geoloc)\n",
    "            \n",
    "            if len(geolocs) > 2:\n",
    "                # remove the farthest outlier\n",
    "                lats, lngs = [loc['lat'] for loc in geolocs], [loc['lng'] for loc in geolocs]\n",
    "                mean_lat, mean_lng = np.mean(lats), np.mean(lngs)  # get the centroid\n",
    "                x = get_outlier_idx(\n",
    "                    (mean_lat, mean_lng), \n",
    "                    [(lat, lng) for lat, lng in zip(lats, lngs)]\n",
    "                )\n",
    "                del geolocs[x]\n",
    "                del locs[x]\n",
    "                # get the index of location with the smallest region\n",
    "                j = get_smallest_region_idx(geolocs)\n",
    "                location = locs[j]\n",
    "                lat, lng = geolocs[j]['lat'], geolocs[j]['lng']\n",
    "                ne, sw = geolocs[j]['northeast'], geolocs[j]['southwest']\n",
    "            elif len(geolocs) == 2:\n",
    "                j = get_smallest_region_idx(geolocs)\n",
    "                location = locs[j]\n",
    "                lat, lng = geolocs[j]['lat'], geolocs[j]['lng']\n",
    "                ne, sw = geolocs[j]['northeast'], geolocs[j]['southwest']\n",
    "            elif len(geolocs) == 1:\n",
    "                location = locs[0]\n",
    "                lat, lng = geolocs[0]['lat'], geolocs[0]['lng']\n",
    "                ne, sw = geolocs[0]['northeast'], geolocs[0]['southwest']\n",
    "            else:\n",
    "                print(f\"Locations in document {i} cannot be geocoded!\")\n",
    "                location, lat, lng, ne, sw = None, None, None, None, None\n",
    "        else:\n",
    "            result['locations'][i] = None\n",
    "            location, lat, lng, ne, sw = None, None, None, None, None\n",
    "        \n",
    "        result['location'][i] = location\n",
    "        result['latitude'][i], result['longitude'][i] = lat, lng\n",
    "        result['diameter_km'][i] = get_distance(ne, sw)\n",
    "    \n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7d5ccd-8aaf-4a45-aee9-92ac0b0cf9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All locations in document 76 are empty!\n",
      "All locations in document 94 are empty!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locations</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>diameter_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cortez|Telluride|</td>\n",
       "      <td>Telluride</td>\n",
       "      <td>37.935800</td>\n",
       "      <td>-107.848050</td>\n",
       "      <td>1.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lillooet|British Columbia|the Fraser River</td>\n",
       "      <td>Lillooet</td>\n",
       "      <td>50.683333</td>\n",
       "      <td>-121.933330</td>\n",
       "      <td>14.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kavalapara|Kerala|Malappuram|</td>\n",
       "      <td>Kavalapara</td>\n",
       "      <td>10.768050</td>\n",
       "      <td>76.302740</td>\n",
       "      <td>3.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baglung|</td>\n",
       "      <td>Baglung</td>\n",
       "      <td>28.271890</td>\n",
       "      <td>83.589760</td>\n",
       "      <td>5.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vancouver|</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>49.261636</td>\n",
       "      <td>-123.113350</td>\n",
       "      <td>21.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Gunma Prefecture|Tomioka|</td>\n",
       "      <td>Tomioka</td>\n",
       "      <td>36.259624</td>\n",
       "      <td>138.889437</td>\n",
       "      <td>45.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Sorsogon|Albay|Catanduanes|Northern Samar|East...</td>\n",
       "      <td>Sorsogon</td>\n",
       "      <td>12.984820</td>\n",
       "      <td>123.997150</td>\n",
       "      <td>34.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Palawan|Caraga|Visayas|Davao Region</td>\n",
       "      <td>Caraga</td>\n",
       "      <td>7.331090</td>\n",
       "      <td>126.562110</td>\n",
       "      <td>39.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>West Seattle|Alki Beach|Seattle|Bellevue|Wilbu...</td>\n",
       "      <td>Alki Beach</td>\n",
       "      <td>47.592020</td>\n",
       "      <td>-122.382380</td>\n",
       "      <td>1.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Mumbai|Shivaji Nagar</td>\n",
       "      <td>Shivaji Nagar</td>\n",
       "      <td>25.890320</td>\n",
       "      <td>85.983430</td>\n",
       "      <td>19.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             locations       location  \\\n",
       "0                                    Cortez|Telluride|      Telluride   \n",
       "1           Lillooet|British Columbia|the Fraser River       Lillooet   \n",
       "3                        Kavalapara|Kerala|Malappuram|     Kavalapara   \n",
       "4                                             Baglung|        Baglung   \n",
       "5                                           Vancouver|      Vancouver   \n",
       "..                                                 ...            ...   \n",
       "100                          Gunma Prefecture|Tomioka|        Tomioka   \n",
       "101  Sorsogon|Albay|Catanduanes|Northern Samar|East...       Sorsogon   \n",
       "102                Palawan|Caraga|Visayas|Davao Region         Caraga   \n",
       "103  West Seattle|Alki Beach|Seattle|Bellevue|Wilbu...     Alki Beach   \n",
       "104                               Mumbai|Shivaji Nagar  Shivaji Nagar   \n",
       "\n",
       "      latitude   longitude  diameter_km  \n",
       "0    37.935800 -107.848050        1.416  \n",
       "1    50.683333 -121.933330       14.497  \n",
       "3    10.768050   76.302740        3.111  \n",
       "4    28.271890   83.589760        5.921  \n",
       "5    49.261636 -123.113350       21.267  \n",
       "..         ...         ...          ...  \n",
       "100  36.259624  138.889437       45.978  \n",
       "101  12.984820  123.997150       34.399  \n",
       "102   7.331090  126.562110       39.382  \n",
       "103  47.592020 -122.382380        1.342  \n",
       "104  25.890320   85.983430       19.719  \n",
       "\n",
       "[102 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = pd.read_csv('../data/test_examples_100.csv', index_col=0)\n",
    "results = predict(example, model) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c510560f-4516-4cf1-97f9-04eaac71f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('test_locations_v2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
